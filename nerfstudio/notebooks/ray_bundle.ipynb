{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerfstudio.pipelines.imaginedriving_pipeline import ImagineDrivingPipelineConfig, ImagineDrivingPipeline\n",
    "from nerfstudio.data.datamanagers.ad_datamanager import ADDataManagerConfig, ADDataManager\n",
    "from nerfstudio.data.dataparsers.pandaset_dataparser import PandaSetDataParserConfig\n",
    "\n",
    "from nerfstudio.cameras.camera_optimizers import CameraOptimizerConfig\n",
    "from nerfstudio.models.neurad import NeuRADModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s0001899/Dev/neurad-studio\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /home/s0001899/Dev/neurad-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_target': nerfstudio.pipelines.imaginedriving_pipeline.ImagineDrivingPipeline,\n",
       " 'datamanager': {'_target': nerfstudio.data.datamanagers.ad_datamanager.ADDataManager,\n",
       "  'data': None,\n",
       "  'masks_on_gpu': False,\n",
       "  'images_on_gpu': False,\n",
       "  'dataparser': {'_target': nerfstudio.data.dataparsers.pandaset_dataparser.PandaSet,\n",
       "   'data': PosixPath('data/pandaset'),\n",
       "   'sequence': '001',\n",
       "   'train_split_fraction': 0.5,\n",
       "   'train_eval_split_type': <SplitTypes.LINSPACE: 'linspace'>,\n",
       "   'max_eval_frames': None,\n",
       "   'dataset_start_fraction': 0.0,\n",
       "   'dataset_end_fraction': 1.0,\n",
       "   'cameras': ('front', 'front_left', 'front_right', 'back', 'left', 'right'),\n",
       "   'lidars': ('Pandar64',),\n",
       "   'min_lidar_dist': (1.0, 2.0, 2.0),\n",
       "   'radars': (),\n",
       "   'load_cuboids': True,\n",
       "   'include_deformable_actors': False,\n",
       "   'annotation_interval': 0.1,\n",
       "   'rolling_shutter_offsets': (-0.03, 0.01),\n",
       "   'allow_per_point_times': True,\n",
       "   'add_missing_points': True,\n",
       "   'lidar_elevation_mapping': {'Pandar64': {0: 14.882,\n",
       "     1: 11.032,\n",
       "     2: 8.059,\n",
       "     3: 5.057,\n",
       "     4: 3.04,\n",
       "     5: 2.028,\n",
       "     6: 1.86,\n",
       "     7: 1.688,\n",
       "     8: 1.522,\n",
       "     9: 1.351,\n",
       "     10: 1.184,\n",
       "     11: 1.013,\n",
       "     12: 0.846,\n",
       "     13: 0.675,\n",
       "     14: 0.508,\n",
       "     15: 0.337,\n",
       "     16: 0.169,\n",
       "     17: 0.0,\n",
       "     18: -0.169,\n",
       "     19: -0.337,\n",
       "     20: -0.508,\n",
       "     21: -0.675,\n",
       "     22: -0.846,\n",
       "     23: -1.013,\n",
       "     24: -1.184,\n",
       "     25: -1.351,\n",
       "     26: -1.522,\n",
       "     27: -1.688,\n",
       "     28: -1.86,\n",
       "     29: -2.028,\n",
       "     30: -2.198,\n",
       "     31: -2.365,\n",
       "     32: -2.536,\n",
       "     33: -2.7,\n",
       "     34: -2.873,\n",
       "     35: -3.04,\n",
       "     36: -3.21,\n",
       "     37: -3.375,\n",
       "     38: -3.548,\n",
       "     39: -3.712,\n",
       "     40: -3.884,\n",
       "     41: -4.05,\n",
       "     42: -4.221,\n",
       "     43: -4.385,\n",
       "     44: -4.558,\n",
       "     45: -4.72,\n",
       "     46: -4.892,\n",
       "     47: -5.057,\n",
       "     48: -5.229,\n",
       "     49: -5.391,\n",
       "     50: -5.565,\n",
       "     51: -5.726,\n",
       "     52: -5.898,\n",
       "     53: -6.061,\n",
       "     54: -7.063,\n",
       "     55: -8.059,\n",
       "     56: -9.06,\n",
       "     57: -9.885,\n",
       "     58: -11.032,\n",
       "     59: -12.006,\n",
       "     60: -12.974,\n",
       "     61: -13.93,\n",
       "     62: -18.889,\n",
       "     63: -24.897}},\n",
       "   'skip_elevation_channels': {'Pandar64': (62, 63)},\n",
       "   'lidar_azimuth_resolution': {'Pandar64': 0.2},\n",
       "   'paint_points': False,\n",
       "   'correct_cuboid_time': True},\n",
       "  'train_num_rays_per_batch': 40960,\n",
       "  'train_num_images_to_sample_from': -1,\n",
       "  'train_num_times_to_repeat_images': -1,\n",
       "  'eval_num_rays_per_batch': 40960,\n",
       "  'eval_num_images_to_sample_from': -1,\n",
       "  'eval_num_times_to_repeat_images': -1,\n",
       "  'eval_image_indices': (0,),\n",
       "  'collate_fn': <function nerfstudio.data.utils.nerfstudio_collate.nerfstudio_collate(batch: Any, extra_mappings: Optional[Dict[type, Callable]] = None) -> Any>,\n",
       "  'camera_res_scale_factor': 1.0,\n",
       "  'patch_size': 1,\n",
       "  'camera_optimizer': None,\n",
       "  'pixel_sampler': {'_target': nerfstudio.data.pixel_samplers.ScaledPatchSampler,\n",
       "   'num_rays_per_batch': 4096,\n",
       "   'keep_full_image': False,\n",
       "   'is_equirectangular': False,\n",
       "   'ignore_mask': False,\n",
       "   'fisheye_crop_radius': None,\n",
       "   'rejection_sample_mask': True,\n",
       "   'max_num_iterations': 100,\n",
       "   'patch_scale': 1,\n",
       "   'patch_size': 1},\n",
       "  'num_processes': 8,\n",
       "  'queue_size': 8,\n",
       "  'max_thread_workers': 1,\n",
       "  'train_num_lidar_rays_per_batch': 16384,\n",
       "  'eval_num_lidar_rays_per_batch': 8192,\n",
       "  'downsample_factor': 1,\n",
       "  'image_divisible_by': 3},\n",
       " 'model': {'_target': nerfstudio.models.neurad.NeuRADModel,\n",
       "  'enable_collider': True,\n",
       "  'collider_params': {'near_plane': 2.0, 'far_plane': 6.0},\n",
       "  'loss_coefficients': {'rgb_loss_coarse': 1.0, 'rgb_loss_fine': 1.0},\n",
       "  'eval_num_rays_per_chunk': 32768,\n",
       "  'prompt': None,\n",
       "  'rgb_upsample_factor': 3,\n",
       "  'dynamic_actors': {'_target': nerfstudio.model_components.dynamic_actors.DynamicActors,\n",
       "   'optimize_trajectories': True,\n",
       "   'actor_bbox_padding': (0.25, 0.25, 0.1)},\n",
       "  'camera_optimizer': {'_target': nerfstudio.cameras.camera_optimizers.CameraOptimizer,\n",
       "   'mode': 'off',\n",
       "   'trans_l2_penalty': 0.01,\n",
       "   'rot_l2_penalty': 0.001,\n",
       "   'optimizer': None,\n",
       "   'scheduler': None},\n",
       "  'loss': {'vgg_mult': 0.05,\n",
       "   'rgb_mult': 5.0,\n",
       "   'depth_mult': 0.01,\n",
       "   'intensity_mult': 0.1,\n",
       "   'carving_mult': 0.01,\n",
       "   'carving_epsilon': 0.1,\n",
       "   'quantile_threshold': 0.95,\n",
       "   'interlevel_loss_mult': 0.001,\n",
       "   'distortion_loss_mult': 0.002,\n",
       "   'non_return_lidar_distance': 150.0,\n",
       "   'non_return_loss_mult': 0.1,\n",
       "   'ray_drop_loss_mult': 0.01,\n",
       "   'prop_lidar_loss_mult': 0.1},\n",
       "  'sampling': {'single_jitter': True,\n",
       "   'proposal_field_1': {'_target': nerfstudio.fields.neurad_field.NeuRADProposalField,\n",
       "    'grid': {'_target': nerfstudio.field_components.neurad_encoding.NeuRADHashEncoding,\n",
       "     'static': {'hashgrid_dim': 1,\n",
       "      'num_levels': 6,\n",
       "      'base_res': 128,\n",
       "      'max_res': 4096,\n",
       "      'log2_hashmap_size': 20},\n",
       "     'actor': {'flip_prob': 0.5,\n",
       "      'actor_scale': 10.0,\n",
       "      'hashgrid_dim': 1,\n",
       "      'num_levels': 4,\n",
       "      'base_res': 64,\n",
       "      'max_res': 1024,\n",
       "      'log2_hashmap_size': 15,\n",
       "      'use_4d_hashgrid': True},\n",
       "     'disable_actors': False,\n",
       "     'require_actor_grad': False},\n",
       "    'hidden_dim': 16},\n",
       "   'proposal_field_2': {'_target': nerfstudio.fields.neurad_field.NeuRADProposalField,\n",
       "    'grid': {'_target': nerfstudio.field_components.neurad_encoding.NeuRADHashEncoding,\n",
       "     'static': {'hashgrid_dim': 1,\n",
       "      'num_levels': 6,\n",
       "      'base_res': 128,\n",
       "      'max_res': 4096,\n",
       "      'log2_hashmap_size': 20},\n",
       "     'actor': {'flip_prob': 0.5,\n",
       "      'actor_scale': 10.0,\n",
       "      'hashgrid_dim': 1,\n",
       "      'num_levels': 4,\n",
       "      'base_res': 64,\n",
       "      'max_res': 1024,\n",
       "      'log2_hashmap_size': 15,\n",
       "      'use_4d_hashgrid': True},\n",
       "     'disable_actors': False,\n",
       "     'require_actor_grad': False},\n",
       "    'hidden_dim': 16},\n",
       "   'num_proposal_samples': (128, 64),\n",
       "   'num_nerf_samples': 32,\n",
       "   'power_lambda': -1.0,\n",
       "   'power_scaling': 0.1,\n",
       "   'sky_distance': 20000.0},\n",
       "  'field': {'_target': nerfstudio.fields.neurad_field.NeuRADField,\n",
       "   'grid': {'_target': nerfstudio.field_components.neurad_encoding.NeuRADHashEncoding,\n",
       "    'static': {'hashgrid_dim': 4,\n",
       "     'num_levels': 8,\n",
       "     'base_res': 32,\n",
       "     'max_res': 8192,\n",
       "     'log2_hashmap_size': 22},\n",
       "    'actor': {'flip_prob': 0.25,\n",
       "     'actor_scale': 10.0,\n",
       "     'hashgrid_dim': 4,\n",
       "     'num_levels': 4,\n",
       "     'base_res': 64,\n",
       "     'max_res': 1024,\n",
       "     'log2_hashmap_size': 17,\n",
       "     'use_4d_hashgrid': True},\n",
       "    'disable_actors': False,\n",
       "    'require_actor_grad': True},\n",
       "   'geo_hidden_dim': 32,\n",
       "   'geo_num_layers': 2,\n",
       "   'nff_hidden_dim': 32,\n",
       "   'nff_num_layers': 3,\n",
       "   'nff_out_dim': 32,\n",
       "   'num_multisamples': 1,\n",
       "   'use_sdf': True,\n",
       "   'sdf_beta': 20.0,\n",
       "   'learnable_beta': True},\n",
       "  'appearance_dim': 16,\n",
       "  'use_temporal_appearance': True,\n",
       "  'temporal_appearance_freq': 1.0,\n",
       "  'rgb_hidden_dim': 32,\n",
       "  'implementation': 'tcnn',\n",
       "  'compensate_upsampling_when_rendering': True,\n",
       "  'normalize_depth': False,\n",
       "  'verbose': False},\n",
       " 'calc_fid_steps': (20000,),\n",
       " 'ray_patch_size': (32, 32),\n",
       " 'change_phase_step': 200,\n",
       " 'shift_prob': 0.2,\n",
       " 'rotate_prob': 0.2,\n",
       " 'diffusion_loss_mult': 0.1,\n",
       " 'diffusion_config_path': 'configs/diffusion_model_configs.yml',\n",
       " 'load_diffusion_lora': False,\n",
       " 'lora_weight_path': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "config = ImagineDrivingPipelineConfig(\n",
    "    datamanager=ADDataManagerConfig(\n",
    "        dataparser=PandaSetDataParserConfig(add_missing_points=True)\n",
    "    ),\n",
    "    model=NeuRADModelConfig(\n",
    "        eval_num_rays_per_chunk=1 << 15,\n",
    "        camera_optimizer=CameraOptimizerConfig(mode=\"off\"),  # SO3xR3\n",
    "    ),\n",
    ")\n",
    "asdict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Variable resolution, using variable_res_collate\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Variable resolution, using variable_res_collate\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6eddc904704674b756378dd951a211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90af5165de4147febfce4c2697988a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started processes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Setting up evaluation dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Setting up evaluation dataset\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Caching all <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240</span> images.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Caching all \u001b[1;36m240\u001b[0m images.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09907b4e82c0456ebbf50357f452f217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Caching all <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span> images.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Caching all \u001b[1;36m40\u001b[0m images.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7215ce444543e3a83eb73cf0508cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">4D hashgrid is not supported with torch implementation, falling back multiple grids.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "4D hashgrid is not supported with torch implementation, falling back multiple grids.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">4D hashgrid is not supported with torch implementation, falling back multiple grids.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "4D hashgrid is not supported with torch implementation, falling back multiple grids.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">4D hashgrid is not supported with torch implementation, falling back multiple grids.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "4D hashgrid is not supported with torch implementation, falling back multiple grids.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s0001899/Dev/neurad-studio/neurad-env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/s0001899/Dev/neurad-studio/neurad-env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/s0001899/Dev/neurad-studio/neurad-env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31feb2bd22b24be98d0c565df4bf439c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = ImagineDrivingPipeline(config, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADDataManager(\n",
       "  (train_lidar_ray_generator): LidarRayGenerator()\n",
       "  (eval_ray_generator): RayGenerator()\n",
       "  (eval_lidar_ray_generator): LidarRayGenerator()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.datamanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
