{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "from nerfstudio.cameras.camera_optimizers import CameraOptimizerConfig\n",
    "from nerfstudio.data.datamanagers.ad_datamanager import ADDataManagerConfig\n",
    "from nerfstudio.data.dataparsers.pandaset_dataparser import PandaSetDataParserConfig\n",
    "from nerfstudio.generative.diffusion_model import DiffusionModelConfig, DiffusionModelId, DiffusionModelType\n",
    "from nerfstudio.models.neurad import NeuRADModel, NeuRADModelConfig\n",
    "from nerfstudio.pipelines.diffusion_nerf_pipeline import DiffusionNerfConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating images...: 100%|██████████| 40/40 [01:33<00:00,  2.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import itertools as it\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "def prettify_img(img: torch.Tensor, title: str = \"\"):\n",
    "    img = img.detach().cpu().numpy()\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    pil_image = Image.fromarray((img * 255).astype(\"uint8\")) \n",
    "    return pil_image\n",
    "    \n",
    "\n",
    "models = [\n",
    "    \"un4\", \"un4cn4\", \"un128\", \"un128cn128\"\n",
    "]\n",
    "steps = {\"un4\": 40000, \"un4cn4\": 40000, \"un128\": 25000, \"un128cn128\":  \"40000\"}\n",
    "\n",
    "sequence = \"001\"\n",
    "\n",
    "GEN_TRAINED_DIFFUSION = True\n",
    "if GEN_TRAINED_DIFFUSION:\n",
    "    imgs_dir = Path(\"experiments/Images\")\n",
    "    experiment_name = \"Neurad_Finetuned_Diffusion\"\n",
    "    task_name = \"trained_model\"\n",
    "    img_subdir = imgs_dir / experiment_name / task_name / sequence\n",
    "    img_subdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for model in models:\n",
    "        print(f\"Generating images for model {model}...\")\n",
    "        step = steps[model]\n",
    "        pipe = DiffusionNerfConfig(\n",
    "            max_steps=40001,\n",
    "            calc_fid_steps=tuple(range(0, 40001, 5000)),\n",
    "            ray_patch_size=(128, 128),\n",
    "            nerf_checkpoint=f\"models/diffusionnerf/finetuned-diffusion-{model}/{sequence}/nerfstudio_models/step-0000{step}.ckpt\",\n",
    "            datamanager=ADDataManagerConfig(\n",
    "                dataparser=PandaSetDataParserConfig(add_missing_points=True, cameras=(\"front_left\",), sequence=sequence),\n",
    "                train_num_rays_per_batch=16384,\n",
    "                eval_num_rays_per_batch=16384,\n",
    "                num_processes=0\n",
    "            ),\n",
    "            model=NeuRADModelConfig(\n",
    "                eval_num_rays_per_chunk=1 << 15,\n",
    "                camera_optimizer=CameraOptimizerConfig(mode=\"off\"),  # SO3xR3\n",
    "                rgb_upsample_factor=4,\n",
    "            ),\n",
    "            diffusion_model=DiffusionModelConfig(\n",
    "                dtype=\"fp16\",\n",
    "            ),\n",
    "            augment_phase_step=0,\n",
    "            augment_strategy=\"none\",\n",
    "        ).setup(device=\"cuda\")\n",
    "        pipe.eval()\n",
    "        dataset = pipe.datamanager.eval_dataset\n",
    "        \n",
    "        for img_idx in tqdm.tqdm(range(len(dataset)), desc=\"Generating images...\"):\n",
    "            camera = dataset.cameras[img_idx:img_idx+1].to(device=\"cuda\")\n",
    "            img_gt = dataset.get_image_float32(img_idx).to(device=\"cuda\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                img_out = pipe.model.get_outputs_for_camera(camera)\n",
    "\n",
    "            img_out_pretty = prettify_img(img_out[\"rgb\"])\n",
    "            img_out_name = f\"{img_idx}_{model}.png\"\n",
    "            img_out_path = img_subdir / img_out_name\n",
    "            img_out_pretty.save(img_out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
