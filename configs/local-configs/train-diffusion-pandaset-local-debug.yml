project_name: ImagineDriving

train_batch_size: 1
dataloader_num_workers: 0

n_epochs: 1000
val_freq: 10
checkpointing_steps: 500

train_noise_strength: 0.1
train_noise_num_steps: null

val_noise_num_steps: 50
val_noise_strength: 0.1

learning_rate: 0.0003
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 0.01
adam_epsilon: 0.00000001

lr_scheduler: "constant"
lr_warmup_steps: 1000

#lr_scheduler: "cosine_with_restarts"
#lr_warmup_steps: 1000
#lr_scheduler_kwargs:
#  num_cycles: 2

center_crop: True
flip_prob: 0

#center_crop: False
#flip_prob: 0.5

use_recreation_loss: False

lora_base_ranks:
 unet: 4

models_to_train_lora:
  - unet

logging_dir: logs/finetune/sd
output_dir: outputs/finetune/sd

loggers: ["wandb"]
#loggers: []
